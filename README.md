#Bridging the Domain Gap in Anomaly Detection via Synthetic Data

The project focuses on unsupervised anomaly detection in brain scans. The aim of this project is to overcome the issue of contrast-related domain shift in a VAE-based normative approach. While supervised learning has driven significant advancements in medical image segmentation, the inherent challenges of acquiring labeled data necessitate alternative approaches. Unsupervised anomaly detection methods offer a promising solution, circumventing the need for annotated data by leveraging the core principle of modeling healthy brain anatomy through unsupervised generative learning. This method enables the identification of potential anomalies by detecting deviations from the learned model, even without prior knowledge of specific anomaly appearances, thereby advancing a more efficient approach to medical image analysis.

Researchers employ various generative models, including autoencoders (AEs), variational autoencoders (VAEs), and generative adversarial networks (GANs), to model the normative distribution of healthy data. This approach relies on the assumption that models trained solely on healthy samples will struggle to accurately reconstruct pathological (anomalous) data. The resulting reconstruction errors can then be used to identify potential anomalies within unseen data.

Despite the advantages of unsupervised anomaly detection models trained on real medical scans, their generalizability is limited by domain shifts due to continuous changes in imaging parameters. For example, a model trained on T1-weighted images will not be able to detect anomalies in T2-weighted images. While synthetic images generated through Generative Adversarial Networks (GANs) have been used to mitigate domain shift issues in unsupervised anomaly detection, GANs are constrained to generating images within the training distribution, restricting model performance on out-of-distribution data. To overcome the limited generalizability of GAN-generated synthetic data, the project proposes a domain-agnostic synthetic data generation method using Gaussian Mixture Models (GMMs). Through domain randomization, we assign distinct Gaussian distributions to various brain tissue types using GMMs, simulating diverse image parameter scenarios the model might encounter during testing. This approach ensures the model's resilience to image artifacts, attributing anomalies solely to genuine physiological brain changes. 
